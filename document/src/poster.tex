%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% a0poster Landscape Poster - REVAMPED STYLE
% Original Template from: http://www.LaTeXTemplates.com
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%   PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[a0,landscape]{config/poster/a0poster}
\usepackage{config/poster/a0size}

% Core Packages
\usepackage{multicol} % For multiple columns
\usepackage[svgnames]{xcolor} % For custom colors
\usepackage{times} % Use the times font
\usepackage{graphicx} % For including images
\usepackage{booktabs} % For professional tables
\usepackage[font=small,labelfont=bf]{caption} % For figure/table captions
\usepackage{amsfonts, amsmath, amsthm, amssymb} % Math packages
\usepackage[style=ieee]{biblatex} % IEEE style citations

% Styling Packages
\usepackage[most]{tcolorbox} % For creating colored boxes (headers)

\hyphenpenalty=100000
\tolerance=10000

%----------------------------------------------------------------------------------------
%   DOCUMENT CONFIGURATION
%----------------------------------------------------------------------------------------

% Layout settings
\columnsep=80pt % Space between columns
%\columnseprule=3pt % Remove the vertical line for a cleaner look

% Set graphic path
\graphicspath{{./}{resources/chapter-4/}} % Location of the graphics files

% Bibliography resources
\addbibresource{config/paper/IEEEabrv.bib}
\addbibresource{references.bib}

% Custom Colors and Commands
\definecolor{IEEEblue}{rgb}{0.0, 0.21, 0.42} % Define a standard blue for branding

% Command for creating a styled section header
\newcommand{\postersection}[1]{%
  \begin{tcolorbox}[
    colback=IEEEblue,
    colframe=IEEEblue,
    fonttitle=\bfseries,
    coltext=white,
    sharp corners,
    boxrule=0pt,
    top=4pt,
    bottom=4pt,
    halign=center
  ]
    \large #1
  \end{tcolorbox}%
}

%----------------------------------------------------------------------------------------

\begin{document}

%----------------------------------------------------------------------------------------
%   POSTER HEADER 
%----------------------------------------------------------------------------------------

\begin{minipage}[c]{0.8\linewidth}
    \veryHuge \textbf{A Comparative Analysis of Architectural Strategies for Performance Optimization of a Large-Scale Event Ticketing System} \\[1.5cm]
    \LARGE {Akbar Maulana Ridho} \\
    \Large {13521093@std.stei.itb.ac.id} \\
    \Large {Teknik Informatika, Institut Teknologi Bandung}
\end{minipage}

\vspace{1cm} % Whitespace between header and content

%----------------------------------------------------------------------------------------
%   POSTER BODY
%----------------------------------------------------------------------------------------

\begin{multicols}{4} % Use 4 columns for the body

    %----------------------------------------------------------------------------------------
    %   ABSTRACT
    %----------------------------------------------------------------------------------------

    \postersection{Abstract}
    \begin{quote}
        High-demand event ticketing systems require high throughput and stability under extreme query loads and seat contention. This paper investigates database and application-level optimizations to address these challenges. We evaluate the performance of a traditional PostgreSQL cluster against distributed SQL databases, specifically CitusData and YugabyteDB, for scaling transaction rates. Additionally, we introduce an asynchronous, concurrency-limited order processing flow control scheme designed to reduce database strain by rejecting invalid requests early. Under load tests with 10,000 to 15,000 virtual users, the baseline PostgreSQL cluster demonstrated superior performance with the lowest latency and most efficient resource utilization. In contrast, CitusData showed acceptable but higher latency, while YugabyteDB exhibited poor performance and an unacceptable failure rate. The flow control mechanism, when applied to the PostgreSQL cluster, proved highly effective, significantly reducing database load by pre-emptively filtering requests for unavailable tickets. Our findings suggest that for this specific high-contention workload, a well-tuned monolithic relational database combined with an intelligent application-level flow control strategy provides a more robust and efficient solution than the tested distributed database alternatives.
    \end{quote}

    %----------------------------------------------------------------------------------------
    %   INTRODUCTION
    %----------------------------------------------------------------------------------------

    \postersection{Introduction}
    Online ticket sales for major events present immense technical challenges. High-profile sales, like Taylor Swift's "The Eras Tour," have seen system failures due to overwhelming demand, where millions of users attempt to buy tickets simultaneously \cite{swiftTicketmaster}. This highlights a critical need for systems that can handle extreme, sudden spikes in traffic without failing.

    Ticketing systems face a unique load profile:
    \begin{itemize}
        \item \textbf{Exponential User Arrival:} A massive number of users access the system in a very short window.
        \item \textbf{High Read/Write Load:} Users constantly check for available tickets (reads) while simultaneously trying to purchase them (writes).
        \item \textbf{Extreme Resource Contention:} Many users compete for the exact same limited resources (seats).
    \end{itemize}
    This research investigates various architectural solutions to build a reliable, high-performance ticketing system capable of withstanding these conditions.

    %----------------------------------------------------------------------------------------
    %   OBJECTIVES
    %----------------------------------------------------------------------------------------

    \postersection{Main Objectives}
    This study aims to formulate an optimal and reliable solution for large-scale ticket sales systems by focusing on four key challenges:
    \begin{enumerate}
        \item \textbf{Increase Transaction Throughput:} Evaluate and compare different database architectures (standard vs. distributed) to scale write operations effectively.
        \item \textbf{Optimize Read Operations:} Design and test a multi-layered caching strategy to handle high-volume queries for ticket availability.
        \item \textbf{Ensure Data Integrity:} Implement robust mechanisms within the database to prevent critical errors like double-booking under high concurrency.
        \item \textbf{Maintain System Stability:} Develop and assess an application-level order processing flow control mechanism to manage request spikes and prevent system overload.
    \end{enumerate}

    %----------------------------------------------------------------------------------------
    %   MATERIALS AND METHODS
    %----------------------------------------------------------------------------------------

    \postersection{Methods and Materials}
    \subsection*{Architectures and Technologies}
    We compared three PostgreSQL-compatible database architectures:
    \begin{itemize}
        \item \textbf{PostgreSQL Cluster:} A standard primary-replica setup serving as the performance baseline.
        \item \textbf{CitusData:} A PostgreSQL extension that creates a distributed, coordinator-worker database architecture \cite{citus}.
        \item \textbf{YugabyteDB:} A fully distributed SQL database using the Raft consensus protocol for high availability \cite{yugabyte}.
    \end{itemize}

    To manage the high load, we implemented two key optimization strategies:
    \begin{itemize}
        \item \textbf{Caching with Redis:} An in-memory Redis cluster was used to cache aggregated data (e.g., ticket availability per section) to offload high-volume read queries from the main database.
        \item \textbf{Flow Control with RabbitMQ:} An asynchronous order processing system was designed. This system first rejects requests for unavailable seats via a Redis pre-check, then places valid requests into a RabbitMQ message queue. This approach controls the rate of transactions hitting the database, preventing overload from traffic spikes.
    \end{itemize}

    \subsection*{Testing Methodology}
    We used the K6 load testing tool to simulate 10,000-15,000 virtual users (VUs). To mimic realistic buyer behavior, VUs were assigned diverse profiles with varying ticket preferences and persistence in retrying failed attempts. Two primary scenarios were executed:
    \begin{enumerate}
        \item \textbf{Sustained Load Test:} A constant, high number of VUs were active for 10-15 minutes to measure the system's stability and maximum throughput under continuous stress.
        \item \textbf{Ticket Scramble (Spike Test):} A massive initial spike in users, simulated with a log-normal arrival rate, was used to test the system's response to a sudden "ticket drop" event.
    \end{enumerate}
    System performance, including latency, throughput, error rates, and resource utilization, was closely monitored using Prometheus for metrics collection and Grafana for visualization.

    %----------------------------------------------------------------------------------------
    %   RESULTS 
    %----------------------------------------------------------------------------------------

    \postersection{Results}
    \subsection*{Database Performance Comparison}
    The baseline \textbf{PostgreSQL cluster} significantly outperformed the distributed databases. Its monolithic nature avoided the network and coordination overhead inherent in distributed systems, proving more efficient for numerous small, fast transactions. \textbf{CitusData}'s performance was acceptable but was bottlenecked by its coordinator node, leading to ~2x higher latency for this type of workload \cite{Slot2020}. The Raft-based consensus mechanism in \textbf{YugabyteDB} introduced high latency (\textgreater4x) and resource costs, making it unsuitable for this high-contention use case.

    \begin{center}\vspace{0.5cm}
        \captionof{table}{Overall Performance of Order Processing}
        \begin{tabular}{l l l l}
            \toprule
            \textbf{Metric} & \textbf{PostgreSQL} & \textbf{CitusData} & \textbf{YugabyteDB} \\
            \midrule
            Max Throughput  & 466 rps             & 410 rps            & 216 rps             \\
            Peak CPU Usage  & 8 vCPU              & 10 vCPU            & 19 vCPU             \\
            Peak Memory     & 3.4 GB              & 5 GB               & 36 GB               \\
            Latency (P50)   & 192-382 ms          & 496-650 ms         & 854-10k ms          \\
            \bottomrule
        \end{tabular}
    \end{center}\vspace{0.5cm}

    \subsection*{Read Query Optimization}
    The multi-layered caching strategy yielded mixed results:
    \begin{itemize}
        \item \textbf{Highly Effective:} Caching aggregated seat availability (e.g., seats left per section) in Redis successfully offloaded significant traffic from the database, handling up to \textbf{1700 rps} with an average latency of only \textbf{2.5-4.5 ms}.
        \item \textbf{Ineffective:} A short-lived (150 ms) in-memory cache for granular, individual seat availability had a very low hit ratio. The local nature of the cache per application instance and wide distribution of user requests made this approach a bottleneck, with P95 latencies up to 7 seconds.
    \end{itemize}

    \subsection*{Flow Control Mechanism}
    The flow control system was highly beneficial for system stability:
    \begin{itemize}
        \item \textbf{Early Request Rejection:} Pre-checking ticket availability against Redis before queueing was extremely effective. It reduced latency for failed booking attempts from over 1-2 seconds down to just \textbf{50-100 ms}, significantly lessening useless load on the database.
        \item \textbf{Queued Processing:} Using RabbitMQ to buffer requests successfully smoothed out traffic spikes and reduced database contention. However, it introduced significant end-to-end latency, indicating a trade-off between stability and responsiveness. The test load was not high enough to fully overwhelm the non-queued system, where this pattern would provide maximum benefit.
    \end{itemize}

    \subsection*{Data Integrity}
    Throughout all high-contention tests, the use of transactional row-level locking (\texttt{SELECT ... FOR UPDATE}) in PostgreSQL proved completely robust. Sanity checks confirmed \textbf{zero instances of double-booked seats}, validating the reliability of this approach for handling race conditions.

    %----------------------------------------------------------------------------------------
    %   CONCLUSIONS
    %----------------------------------------------------------------------------------------

    \columnbreak

    \postersection{Conclusions}
    \begin{itemize}
        \item For high-contention transactional workloads, a well-tuned \textbf{monolithic PostgreSQL database offers superior performance} and efficiency compared to the tested distributed solutions.
        \item The overhead of coordination in CitusData and YugabyteDB outweighed their scaling benefits for this specific use case.
        \item \textbf{Flow control, especially early request rejection}, is a critical strategy for maintaining system stability during traffic spikes.
        \item Offloading aggregate read queries to an in-memory store like \textbf{Redis is highly effective}, but fine-grained caching needs a more sophisticated, distributed approach.
    \end{itemize}

    %----------------------------------------------------------------------------------------
    %   FUTURE WORK
    %----------------------------------------------------------------------------------------

    \postersection{Future Work}
    Future work should focus on:
    \begin{enumerate}
        \item Exploring more advanced, distributed caching strategies for granular data.
        \item Implementing a lower-latency queueing mechanism to reduce overhead.
        \item Testing the architecture under extreme loads (\textgreater100,000 VUs) to find the breaking point of the monolithic setup.
    \end{enumerate}

    \postersection{Acknowledgements}
    The author thanks his supervisor, Achmad Imam Kistijantoro, S.T., M.Sc., Ph.D., and Dr.techn. Saiful Akbar, S.T., M.T., for their invaluable guidance. Gratitude is also extended to the academic staff of Informatics Engineering at ITB.

    %----------------------------------------------------------------------------------------
    %   REFERENCES
    %----------------------------------------------------------------------------------------

    \postersection{References}
    \printbibliography[heading=none]

\end{multicols}
\end{document}